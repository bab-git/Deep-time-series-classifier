#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Model quantization


Created on Mon Jan 13 13:52:21 2020

@author: bhossein
"""

import time
#from collections import defaultdict
#from functools import partial
#from multiprocessing import cpu_count
#from pathlib import Path
#from textwrap import dedent
import matplotlib.pyplot as plt
import numpy as np
#import pandas as pd

#from sklearn.externals import joblib
#from sklearn.model_selection import train_test_split
#from sklearn.preprocessing import LabelEncoder, StandardScaler

#import torch

from torch import nn
#from torch import optim
from torch.nn import functional as F
#from torch.optim.lr_scheduler import _LRScheduler
#from torch.utils.data import TensorDataset, DataLoader
#import datetime
#import pickle
#from git import Repo

from torchsummary import summary

import os
#abspath = os.path.abspath('test_classifier_GPU_load.py')
#dname = os.path.dirname(abspath)
#os.chdir(dname)

os.chdir('/home/bhossein/BMBF project/code_repo')
#os.chdir('C:\Hinkelstien\code_repo')

from my_data_classes import create_datasets_file, create_loaders, smooth, create_datasets_win
import my_net_classes
from my_net_classes import SepConv1d, _SepConv1d, Flatten, parameters
import torch
import pickle
#%%===============  loading a learned model

#save_name = "1d_6con_2K_win_test_30"
save_name = "1d_6con_b512_trim_2K_win"
#save_name = "1d_6con_b512_trim_2K_win_s11"
#save_name = "1d_6con_b512_trim_2K_win_s3"

#save_name = "1d_6con_b512_trim_2K_seed2"
#save_name = "1dconv_b512_t4K"
#save_name = "1dconv_b512_drop1B"
#save_name = "1dconv_b512_drop1"
#save_name = "batch_512_BN_B"
#save_name = "1dconv_b512_BNM_B"
#save_name = "1dconv_b512_BNA_B"
#save_name = "batch_512_BNA"
#save_name = "batch_512_BN"
#save_name = "batch_512_B"
#t_stamp = "_batch_512_11_29_17_03"

save_name2 = input("Input model to load (currently "+save_name+" is selected) :")
if save_name2 != '':
    save_name = save_name2

print(save_name + " is loaded.")

load_ECG =  torch.load ('raw_x_8K_sync_win2K.pt')
#load_ECG =  torch.load ('raw_x_8K_sync.pt') 
#load_ECG =  torch.load ('raw_x_4k_5K.pt') 
#load_ECG =  torch.load ('raw_x_all.pt') 

loaded_vars = pickle.load(open("train_"+save_name+"_variables.p","rb"))
#loaded_file = pickle.load(open("variables"+t_stamp+".p","rb"))
#loaded_file = pickle.load(open("variables_ended"+t_stamp+".p","rb"))

params = loaded_vars['params']
epoch = params.epoch
print('epoch: %d ' % (epoch))
seed = params.seed
test_size = params.test_size
np.random.seed(seed)
t_range = params.t_range

cuda_num = input("cuda number:")
#cuda_num = 0

device = torch.device('cuda:'+str(cuda_num) if torch.cuda.is_available() and cuda_num != 'cpu' else 'cpu')
#device = torch.device('cpu')

raw_x = load_ECG['raw_x']
#raw_x = load_ECG['raw_x'].to(device)
target = load_ECG['target']
data_tag = load_ECG['data_tag']
if type(target) != 'torch.Tensor':
    target = torch.tensor(load_ECG['target']).to(device)


dataset_splits = create_datasets_win(raw_x, target, data_tag, test_size, seed=seed, t_range = t_range, device = device)
ecg_datasets = dataset_splits[0:3]
trn_idx, val_idx, tst_idx = dataset_splits[3:6]
#ecg_datasets = create_datasets_file(raw_x, target, test_size, seed=seed, t_range = t_range, device = device)


acc_history = loaded_vars['acc_history']
loss_history = loaded_vars['loss_history']
#ecg_datasets = loaded_split['ecg_datasets']
trn_ds, val_ds, tst_ds = ecg_datasets

batch_size = loaded_vars['params'].batch_size
trn_dl, val_dl, tst_dl = create_loaders(ecg_datasets, bs=batch_size, jobs = 0)
raw_feat = ecg_datasets[0][0][0].shape[0]
raw_size = ecg_datasets[0][0][0].shape[1]
num_classes = 2

#device = ecg_datasets[0].tensors[0].device
#device = torch.device('cuda:4' if torch.cuda.is_available() else 'cpu')


model = my_net_classes.Classifier_1d_6_conv_ver1(raw_feat, num_classes, raw_size, batch_norm = True).to(device)
#model = my_net_classes.Classifier_1d_6_conv(raw_feat, num_classes, raw_size, batch_norm = True).to(device)
#model = my_net_classes.Classifier_1dconv(raw_feat, num_classes, raw_size).to(device)
#model = my_net_classes.Classifier_1dconv(raw_feat, num_classes, raw_size, batch_norm = True).to(device)
#model = my_net_classes.Classifier_1dconv_BN(raw_feat, num_classes, raw_size, batch_norm = True).to(device)

if torch.cuda.is_available()*0:
#    model.load_state_dict(torch.load("train_"+save_name+'_best.pth'))
    model.load_state_dict(torch.load("train_"+save_name+'_best.pth', map_location=lambda storage, loc: storage.cuda('cuda:'+str(cuda_num))))
else:
    model.load_state_dict(torch.load("train_"+save_name+'_best.pth', map_location=lambda storage, loc: storage))


#model = Classifier_1dconv(raw_feat, num_classes, raw_size/(2*4**3)).to(device)
#model.load_state_dict(torch.load("train_"+save_name+'_best.pth'))


s = time.time()
model.eval()
correct, total , total_P, TP , FP = 0, 0, 0, 0, 0

batch = []
i_error = []
list_pred = []
with torch.no_grad():
    for i_batch, batch in enumerate(tst_dl):
        x_raw, y_batch = [t.to('cpu') for t in batch]
        list_x = list(range(i_batch*tst_dl.batch_size,min((i_batch+1)*tst_dl.batch_size,len(tst_ds))))
    #    x_raw, y_batch = [t.to(device) for t in batch]
    #    x_raw, y_batch = tst_ds.tensors
        #x_raw, y_batch = [t.to(device) for t in val_ds.tensors]
        out = model(x_raw)
        preds = F.log_softmax(out, dim = 1).argmax(dim=1)
    #    preds = F.log_softmax(out, dim = 1).argmax(dim=1).to('cpu')
        list_pred = np.append(list_pred,preds.tolist())
    #    list_pred = np.append(list_pred,preds.tolist())
        total += y_batch.size(0)
        correct += (preds ==y_batch).sum().item()    
    #    i_error = np.append(i_error,np.where(preds !=y_batch))
        i_error = np.append(i_error,[list_x[i] for i in np.where((preds !=y_batch).to('cpu'))[0]])
    #    TP += ((preds ==y_batch) & (1 ==y_batch)).sum().item()
    #    total_P += (1 ==y_batch).sum().item()
    #    FP += ((preds !=y_batch) & (0 ==y_batch)).sum().item()

elapsed = time.time() - s
print('''nelapsed time (seconds): {0:.2f}'''.format(elapsed))
    
acc = correct / total * 100
#TP_rate = TP / total_P *100
#FP_rate = FP / (total-total_P) *100

print('Accuracy on all windows of test data:  %2.2f' %(acc))

#TP_rate = TP / (1 ==y_batch).sum().item() *100
#FP_rate = FP / (0 ==y_batch).sum().item() *100


win_size = (data_tag==0).sum()
#thresh_AF = win_size /2
thresh_AF = 3

list_ECG = np.unique([data_tag[i] for i in tst_idx])
#list_ECG = np.unique([data_tag[i] for i in tst_idx if target[i] == label])
#len(list_error_ECG)/8000*100

TP_ECG, FN_ECG , total_P, total_N = np.zeros(4)
list_pred_win = 100*np.ones([len(list_ECG), win_size])
for i_row, i_ecg in enumerate(list_ECG):
    list_win = np.where(data_tag==i_ecg)[0]
    pred_win = [list_pred[tst_idx.index(i)] for i in list_win]
#    print(pred_win)
    list_pred_win[i_row,:] = pred_win    
                        
    if i_ecg >8000:   #AF
        total_P +=1
        if (np.array(pred_win)==1).sum() >= thresh_AF:
            TP_ECG += 1                    
    else:         # normal
        total_N +=1
        if (np.array(pred_win)==1).sum() >= thresh_AF:
            FN_ECG += 1
            
    
#TP_ECG_rate = TP_ECG / len(list_ECG) *100
TP_ECG_rate = TP_ECG / total_P *100
FN_ECG_rate = FN_ECG / total_N *100


print("Threshold for detecting AF: %d" % (thresh_AF))
print("TP rate: %2.3f" % (TP_ECG_rate))
print("FN rate: %2.3f" % (FN_ECG_rate))

#print('True positives on test data:  %2.2f' %(TP_rate))
#print('False positives on test data:  %2.2f' %(FP_rate))

#-----------------------  visualize training curve
f, ax = plt.subplots(1,2, figsize=(12,4))    
ax[0].plot(loss_history, label = 'loss')
ax[0].set_title('Validation Loss History: '+save_name)
ax[0].set_xlabel('Epoch no.')
ax[0].set_ylabel('Loss')
ax[0].grid()

ax[1].plot(smooth(acc_history, 5)[:-2], label='acc')
#ax[1].plot(acc_history, label='acc')
ax[1].set_title('Validation Accuracy History: '+save_name)
ax[1].set_xlabel('Epoch no.')
ax[1].set_ylabel('Accuracy');
ax[1].grid()



#checkpoint = torch.load('best_ended_11_27_17_13.pth')
#model.load_state_dict(checkpoint['model_state_dict'])
#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
#epoch = checkpoint['epoch']
#loss = checkpoint['loss']

assert 1==2

model2 = model.to('cpu')
summary(model2, input_size=(raw_feat, raw_size), batch_size = batch_size, device = 'cpu')
#%%===============  checking internal values
drop=.5
batch_norm = True
model1 = nn.Sequential(
            SepConv1d(2,  32, 8, 2, 3, drop=drop, batch_norm = batch_norm),  #out: raw_size/str
            SepConv1d(    32,  64, 8, 4, 2, drop=drop, batch_norm = batch_norm),
            SepConv1d(    64, 128, 8, 4, 2, drop=drop, batch_norm = batch_norm),
            SepConv1d(   128, 256, 8, 4, 2, drop=drop, batch_norm = batch_norm),
            SepConv1d(   256, 512, 8, 4, 2, drop=drop, batch_norm = batch_norm),
            SepConv1d(   512,1024, 8, 4, 2, batch_norm = batch_norm),
#            Flatten(),
#            nn.Linear(256, 64), nn.ReLU(inplace=True),
#            nn.Linear( 64, 64), nn.ReLU(inplace=True)
            ).to(device)
model_out = model1(x_raw)
#model_out = model1(x_raw[0,:,:])
model_out.shape

#%%===============  plot data
i_data = 9000
print('target: '+str(target[i_data]))
plt.figure()
plt.subplot(2,1,1)
plt.plot(raw_x[i_data,0,:])
plt.subplot(2,1,2)
plt.plot(raw_x[i_data,1,:])


# %%================= analyzing i_error
#for i_AF in range(8000):
    
    

list_error_ECG = np.unique([data_tag[tst_idx[i]] for i in i_error.astype(int) if target[tst_idx[i]] == 1])
len(list_error_ECG)/8000*100

list_pred_win = np.zeros([len(list_error_ECG), (data_tag==0).sum()])
for i_row, i_ecg in enumerate(list_error_ECG):
    list_win = np.where(data_tag==i_ecg)[0]
    pred_win = [list_pred[tst_idx.index(i)] for i in list_win]
    print(pred_win)
    list_pred_win[i_row,:] = pred_win

#[i for i in list_win if i in trn_idx ]
    
# %%================= Quantization
model.to('cpu')

model_qn = torch.quantization.quantize_dynamic(
        model, {nn.Linear, nn.Conv1d, nn.BatchNorm1d} , dtype= torch.qint8
        )

summary(model, input_size=(raw_feat, raw_size), batch_size = batch_size, device = 'cpu')
summary(model_qn, input_size=(raw_feat, raw_size), batch_size = batch_size, device = 'cpu')

def print_size_of_model(model):
    torch.save(model.state_dict(), "temp.p")
    print('Size (MB):', os.path.getsize("temp.p")/1e6)
    os.remove('temp.p')


#model_qn.to(device)
model_qn.to('cpu');

s = time.time()
model_qn.eval()

correct, total , total_P, TP , FP = 0, 0, 0, 0, 0

i_error = []
list_pred = []
with torch.no_grad():
    for i_batch, batch in enumerate(tst_dl):
        x_raw, y_batch = [t.to('cpu') for t in batch]
        list_x = list(range(i_batch*tst_dl.batch_size,min((i_batch+1)*tst_dl.batch_size,len(tst_ds))))
        out = model_qn(x_raw)
        preds = F.log_softmax(out, dim = 1).argmax(dim=1)
        list_pred = np.append(list_pred,preds.tolist())
        total += y_batch.size(0)
        correct += (preds ==y_batch).sum().item()    
        i_error = np.append(i_error,[list_x[i] for i in np.where((preds !=y_batch).to('cpu'))[0]])

elapsed = time.time() - s
print('''nelapsed time (seconds): {0:.3f}'''.format(elapsed))
    
acc_q = correct / total * 100

print('Accuracy on all windows of test data:  %2.2f' %(acc_q))

win_size = (data_tag==0).sum()
#thresh_AF = win_size /2
thresh_AF = 3

list_ECG = np.unique([data_tag[i] for i in tst_idx])
#list_ECG = np.unique([data_tag[i] for i in tst_idx if target[i] == label])
#len(list_error_ECG)/8000*100

TP_ECG, FN_ECG , total_P, total_N = np.zeros(4)
list_pred_win = 100*np.ones([len(list_ECG), win_size])
for i_row, i_ecg in enumerate(list_ECG):
    list_win = np.where(data_tag==i_ecg)[0]
    pred_win = [list_pred[tst_idx.index(i)] for i in list_win]
#    print(pred_win)
    list_pred_win[i_row,:] = pred_win    
                        
    if i_ecg >8000:   #AF
        total_P +=1
        if (np.array(pred_win)==1).sum() >= thresh_AF:
            TP_ECG += 1                    
    else:         # normal
        total_N +=1
        if (np.array(pred_win)==1).sum() >= thresh_AF:
            FN_ECG += 1
            
    
#TP_ECG_rate = TP_ECG / len(list_ECG) *100
TP_ECG_rate_q = TP_ECG / total_P *100
FN_ECG_rate_q = FN_ECG / total_N *100


print("Threshold for detecting AF: %d" % (thresh_AF))
print("TP rate: %2.3f" % (TP_ECG_rate_q))
print("FN rate: %2.3f" % (FN_ECG_rate_q))





for name, param in model.named_parameters():
    if param.requires_grad:
        print(name, param.data)
